{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deeplearning CNN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyKlS8eWKaS/hyacKTyqzN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arnoldsynchron/2016-ml-contest/blob/master/Deeplearning_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkZ69ByulsG4",
        "colab_type": "text"
      },
      "source": [
        "# **Deeplearning in Prediction of Geological Facies(Convolution Neural Nets)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2O_tPM9mE_o",
        "colab_type": "text"
      },
      "source": [
        "Prediction of geological surface using available data found in the github [seg](www.github.c0m/seg) repository\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YOEMXIKjKoy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "78d1c6e4-3572-4779-b473-4ce6cf376ca7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# ls '/content/gdrive/My Drive/Data'"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjEAHVW2jvni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from pandas import set_option\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix, f1_score,accuracy_score\n",
        "\n",
        "from collections import Counter\n",
        "import operator\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Convolution1D, Convolution2D, Dense, Input, Dropout, Flatten, MaxPooling2D, Activation, normalization\n",
        "from keras.optimizers import Nadam\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import History\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "np.random.seed(123)"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qn1Pj5qnJ2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(conf):\n",
        "    total_correct = 0.\n",
        "    nb_classes = conf.shape[0]\n",
        "    for i in np.arange(0,nb_classes):\n",
        "        total_correct += conf[i][i]\n",
        "    acc = total_correct/sum(sum(conf))\n",
        "    return acc\n",
        "\n",
        "def label_facies(row, labels):\n",
        "    return labels[ row['Facies'] -1]\n",
        "  \n",
        "def accuracy_adj(conf, adjacent_facies):\n",
        "  total_correct = 0\n",
        "  nb_classes = conf.shape[0]\n",
        "  for i in np.arange(0, nb_classes):\n",
        "    total_correct +=conf[i][i]\n",
        "    for j in adjacent_facies[i]:\n",
        "      total_correct += conf[i][j]\n",
        "  return total_correct/sum(sum(conf))\n",
        "\n",
        "file = pd.read_csv('/content/gdrive/My Drive/Data/train_test_data.csv')"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaFg8KHdheCM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "ccf01f12-757b-46b7-8dcb-dc265b17b5cd"
      },
      "source": [
        "print(file.isna().mean().sort_values(ascending=False))\n",
        "file.head()"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PE           0.184174\n",
            "RELPOS       0.000000\n",
            "NM_M         0.000000\n",
            "PHIND        0.000000\n",
            "DeltaPHI     0.000000\n",
            "               ...   \n",
            "GR           0.000000\n",
            "Depth        0.000000\n",
            "Well Name    0.000000\n",
            "Formation    0.000000\n",
            "Facies       0.000000\n",
            "Length: 11, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Facies</th>\n",
              "      <th>Formation</th>\n",
              "      <th>Well Name</th>\n",
              "      <th>Depth</th>\n",
              "      <th>GR</th>\n",
              "      <th>ILD_log10</th>\n",
              "      <th>DeltaPHI</th>\n",
              "      <th>PHIND</th>\n",
              "      <th>PE</th>\n",
              "      <th>NM_M</th>\n",
              "      <th>RELPOS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2793.0</td>\n",
              "      <td>77.45</td>\n",
              "      <td>0.664</td>\n",
              "      <td>9.9</td>\n",
              "      <td>11.915</td>\n",
              "      <td>4.6</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2793.5</td>\n",
              "      <td>78.26</td>\n",
              "      <td>0.661</td>\n",
              "      <td>14.2</td>\n",
              "      <td>12.565</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2794.0</td>\n",
              "      <td>79.05</td>\n",
              "      <td>0.658</td>\n",
              "      <td>14.8</td>\n",
              "      <td>13.050</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2794.5</td>\n",
              "      <td>86.10</td>\n",
              "      <td>0.655</td>\n",
              "      <td>13.9</td>\n",
              "      <td>13.115</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2795.0</td>\n",
              "      <td>74.58</td>\n",
              "      <td>0.647</td>\n",
              "      <td>13.5</td>\n",
              "      <td>13.300</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.915</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Facies Formation  Well Name   Depth  ...   PHIND   PE  NM_M  RELPOS\n",
              "0       3     A1 SH  SHRIMPLIN  2793.0  ...  11.915  4.6     1   1.000\n",
              "1       3     A1 SH  SHRIMPLIN  2793.5  ...  12.565  4.1     1   0.979\n",
              "2       3     A1 SH  SHRIMPLIN  2794.0  ...  13.050  3.6     1   0.957\n",
              "3       3     A1 SH  SHRIMPLIN  2794.5  ...  13.115  3.5     1   0.936\n",
              "4       3     A1 SH  SHRIMPLIN  2795.0  ...  13.300  3.4     1   0.915\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9B87CMgLuaX",
        "colab_type": "text"
      },
      "source": [
        "# Prediction of PE values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTtkWuZHKoak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "22dd5a9d-b93a-46d5-98ad-baf38059aa34"
      },
      "source": [
        "file[file['PE'].notnull()]"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Facies</th>\n",
              "      <th>Formation</th>\n",
              "      <th>Well Name</th>\n",
              "      <th>Depth</th>\n",
              "      <th>GR</th>\n",
              "      <th>ILD_log10</th>\n",
              "      <th>DeltaPHI</th>\n",
              "      <th>PHIND</th>\n",
              "      <th>PE</th>\n",
              "      <th>NM_M</th>\n",
              "      <th>RELPOS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2793.0</td>\n",
              "      <td>77.450</td>\n",
              "      <td>0.664</td>\n",
              "      <td>9.900</td>\n",
              "      <td>11.915</td>\n",
              "      <td>4.600</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2793.5</td>\n",
              "      <td>78.260</td>\n",
              "      <td>0.661</td>\n",
              "      <td>14.200</td>\n",
              "      <td>12.565</td>\n",
              "      <td>4.100</td>\n",
              "      <td>1</td>\n",
              "      <td>0.979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2794.0</td>\n",
              "      <td>79.050</td>\n",
              "      <td>0.658</td>\n",
              "      <td>14.800</td>\n",
              "      <td>13.050</td>\n",
              "      <td>3.600</td>\n",
              "      <td>1</td>\n",
              "      <td>0.957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2794.5</td>\n",
              "      <td>86.100</td>\n",
              "      <td>0.655</td>\n",
              "      <td>13.900</td>\n",
              "      <td>13.115</td>\n",
              "      <td>3.500</td>\n",
              "      <td>1</td>\n",
              "      <td>0.936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2795.0</td>\n",
              "      <td>74.580</td>\n",
              "      <td>0.647</td>\n",
              "      <td>13.500</td>\n",
              "      <td>13.300</td>\n",
              "      <td>3.400</td>\n",
              "      <td>1</td>\n",
              "      <td>0.915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4974</th>\n",
              "      <td>0</td>\n",
              "      <td>C SH</td>\n",
              "      <td>CRAWFORD</td>\n",
              "      <td>3158.5</td>\n",
              "      <td>86.078</td>\n",
              "      <td>0.554</td>\n",
              "      <td>5.040</td>\n",
              "      <td>16.150</td>\n",
              "      <td>3.161</td>\n",
              "      <td>1</td>\n",
              "      <td>0.639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4975</th>\n",
              "      <td>0</td>\n",
              "      <td>C SH</td>\n",
              "      <td>CRAWFORD</td>\n",
              "      <td>3159.0</td>\n",
              "      <td>88.855</td>\n",
              "      <td>0.539</td>\n",
              "      <td>5.560</td>\n",
              "      <td>16.750</td>\n",
              "      <td>3.118</td>\n",
              "      <td>1</td>\n",
              "      <td>0.611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4976</th>\n",
              "      <td>0</td>\n",
              "      <td>C SH</td>\n",
              "      <td>CRAWFORD</td>\n",
              "      <td>3159.5</td>\n",
              "      <td>90.490</td>\n",
              "      <td>0.530</td>\n",
              "      <td>6.360</td>\n",
              "      <td>16.780</td>\n",
              "      <td>3.168</td>\n",
              "      <td>1</td>\n",
              "      <td>0.583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4977</th>\n",
              "      <td>0</td>\n",
              "      <td>C SH</td>\n",
              "      <td>CRAWFORD</td>\n",
              "      <td>3160.0</td>\n",
              "      <td>90.975</td>\n",
              "      <td>0.522</td>\n",
              "      <td>7.035</td>\n",
              "      <td>16.995</td>\n",
              "      <td>3.154</td>\n",
              "      <td>1</td>\n",
              "      <td>0.556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4978</th>\n",
              "      <td>0</td>\n",
              "      <td>C SH</td>\n",
              "      <td>CRAWFORD</td>\n",
              "      <td>3160.5</td>\n",
              "      <td>90.108</td>\n",
              "      <td>0.513</td>\n",
              "      <td>7.505</td>\n",
              "      <td>17.595</td>\n",
              "      <td>3.125</td>\n",
              "      <td>1</td>\n",
              "      <td>0.528</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4062 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Facies Formation  Well Name   Depth  ...   PHIND     PE  NM_M  RELPOS\n",
              "0          3     A1 SH  SHRIMPLIN  2793.0  ...  11.915  4.600     1   1.000\n",
              "1          3     A1 SH  SHRIMPLIN  2793.5  ...  12.565  4.100     1   0.979\n",
              "2          3     A1 SH  SHRIMPLIN  2794.0  ...  13.050  3.600     1   0.957\n",
              "3          3     A1 SH  SHRIMPLIN  2794.5  ...  13.115  3.500     1   0.936\n",
              "4          3     A1 SH  SHRIMPLIN  2795.0  ...  13.300  3.400     1   0.915\n",
              "...      ...       ...        ...     ...  ...     ...    ...   ...     ...\n",
              "4974       0      C SH   CRAWFORD  3158.5  ...  16.150  3.161     1   0.639\n",
              "4975       0      C SH   CRAWFORD  3159.0  ...  16.750  3.118     1   0.611\n",
              "4976       0      C SH   CRAWFORD  3159.5  ...  16.780  3.168     1   0.583\n",
              "4977       0      C SH   CRAWFORD  3160.0  ...  16.995  3.154     1   0.556\n",
              "4978       0      C SH   CRAWFORD  3160.5  ...  17.595  3.125     1   0.528\n",
              "\n",
              "[4062 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys9F0GqJK4nL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_feature_vectors(data, features, window_width):\n",
        "\n",
        "    raw_feature_vectors = data[features]\n",
        "    well_labels = data['Well Name']\n",
        "    num_features = np.shape(raw_feature_vectors)[1]\n",
        "\n",
        "    output = np.zeros((1, window_width, num_features))\n",
        "    for x in well_labels.unique():\n",
        "        well = raw_feature_vectors[well_labels == x].values\n",
        "        well = np.concatenate((np.repeat(well[0:1], np.floor((window_width-1)/2.0), axis=0), well,\n",
        "                              np.repeat(well[-1:None], np.floor(window_width/2.0), axis=0)), axis=0)\n",
        "\n",
        "        tmp = np.zeros((np.size(well, axis=0) - window_width + 1, window_width, num_features))\n",
        "        for i in np.arange(np.size(well, axis=0) - window_width + 1):\n",
        "            tmp[i] = np.reshape(well[i: i + window_width], (window_width, num_features))\n",
        "\n",
        "        output = np.append(output, tmp, axis=0)\n",
        "\n",
        "    return output[1:]"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVdDQWeUC4nD",
        "colab_type": "text"
      },
      "source": [
        "Remove the P.E values of Stuart and Crawford Wells\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egHEYx6tAPEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def file_copy(file):\n",
        "  data = file.copy()\n",
        "  data = data[data['Well Name'] != 'STUART']\n",
        "  data = data[data['Well Name'] != 'CRAWFORD']\n",
        "  return data"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4KOKyMaJUOC",
        "colab_type": "text"
      },
      "source": [
        "Split Data into Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuOdisI5KkoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2db2e38f-4316-44c8-96d9-b4c0e6c5d79e"
      },
      "source": [
        "data['PE'].isnull().sum()"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "917"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMSdPmyMMAuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "733ded66-38ca-46b0-ed70-fef7b3542ac5"
      },
      "source": [
        "window_width = 15 #Window around the central value\n",
        "data = file_copy(file)\n",
        "feature_list = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'NM_M', 'RELPOS']\n",
        "X_train = prepare_feature_vectors(data[data['PE'].notnull()], feature_list, window_width)\n",
        "num_train_samples = np.asarray(np.shape(X_train))[0]\n",
        "\n",
        "X_test = prepare_feature_vectors(data[data['PE'].isnull()], feature_list, window_width)\n",
        "num_test_samples = np.asarray(np.shape(X_test))[0]\n",
        "\n",
        "print('Training Samples=', num_train_samples, '   Test Samples=', num_test_samples)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Samples= 3232    Test Samples= 917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA81XYK2JmeI",
        "colab_type": "text"
      },
      "source": [
        "Neural Network to Predict the Missing PE Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCH5nbFf1hYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "8654f81f-e9d2-4c47-9d2e-1f34e32fed80"
      },
      "source": [
        "# define neural network to perform regression on PE\n",
        "num_filters = 12\n",
        "dropout_prob = 0.6666\n",
        "\n",
        "cnn = Sequential()\n",
        "cnn.add(Convolution1D(num_filters, 1, border_mode='valid', input_shape=(window_width, len(feature_list))))\n",
        "cnn.add(normalization.BatchNormalization())\n",
        "cnn.add(Activation('tanh'))\n",
        "cnn.add(Convolution1D(num_filters, 3, border_mode='valid'))\n",
        "cnn.add(normalization.BatchNormalization())\n",
        "cnn.add(Activation('tanh'))\n",
        "cnn.add(Dropout(dropout_prob / 2))\n",
        "\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(4*num_filters))\n",
        "cnn.add(normalization.BatchNormalization())\n",
        "cnn.add(Activation('tanh'))\n",
        "cnn.add(Dropout(dropout_prob))\n",
        "\n",
        "cnn.add(Dense(1))\n",
        "cnn.compile(loss='mse', optimizer='rmsprop', metrics=['acc'])\n",
        "cnn.summary()\n",
        "\n",
        "# save initial weights, which are random\n",
        "initial_weights = cnn.get_weights()"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_7 (Conv1D)            (None, 15, 12)            84        \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 15, 12)            48        \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 15, 12)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 13, 12)            444       \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 13, 12)            48        \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 13, 12)            0         \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 13, 12)            0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 156)               0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 48)                7536      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 48)                192       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 48)                0         \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 48)                0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 1)                 49        \n",
            "=================================================================\n",
            "Total params: 8,401\n",
            "Trainable params: 8,257\n",
            "Non-trainable params: 144\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlcUZW2P352m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = data[data['PE'].notnull()]['PE'].values"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDfU570b2r6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define training parameters and prepare arrays to store training metrics\n",
        "epochs_per_fold = 1000\n",
        "num_fold = 5\n",
        "roll_stride = np.ceil(num_train_samples/num_fold).astype(int)\n",
        "\n",
        "cnn_hist = History()\n",
        "hist = np.zeros((4, num_fold, epochs_per_fold))\n",
        "f1scores = np.zeros(num_fold)\n",
        "Y_test = np.zeros((num_test_samples, num_fold))\n",
        "\n",
        "\n",
        "# shuffle input data\n",
        "rand_perm = np.random.permutation(num_train_samples)\n",
        "X_train = X_train[rand_perm]\n",
        "Y_train = Y_train[rand_perm]"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX90RRHp3HQp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "624c6799-2e0d-4e40-b122-4f03747c5bf8"
      },
      "source": [
        "# use 5-fold cross validation and train 5 neural networks, ending up with 5 sets of predictions\n",
        "for i in np.arange(num_fold):\n",
        "    cnn.set_weights(initial_weights)\n",
        "    X_train = np.roll(X_train, i*roll_stride, axis=0)\n",
        "    Y_train = np.roll(Y_train, i*roll_stride, axis=0)\n",
        "\n",
        "    cnn.fit(X_train, Y_train, batch_size=150, nb_epoch=epochs_per_fold, verbose=0,\n",
        "                validation_split=1.0/num_fold, callbacks=[cnn_hist])\n",
        "\n",
        "    # make predictions, i.e. impute PE\n",
        "    Y_test[:, i] = cnn.predict(X_test)[:, 0]\n",
        "\n",
        "    hist[:, i, :] = [cnn_hist.history['acc'], cnn_hist.history['val_acc'],\n",
        "                     cnn_hist.history['loss'], cnn_hist.history['val_loss']]\n",
        "    print(\"Accuracy  =\", np.mean(hist[1, i, -100:]))"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy  = 0.05089644446969032\n",
            "Accuracy  = 0.031715610884130004\n",
            "Accuracy  = 0.04182380210608244\n",
            "Accuracy  = 0.0322720249556005\n",
            "Accuracy  = 0.05210200857371092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATv7kEhQ9j8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSGbwRGg4Lc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "29ce27a1-69ce-49bf-e13a-6dce38da3394"
      },
      "source": [
        "# plot callbacks to evaluate quality of training\n",
        "drop_values = 100\n",
        "drop_hist = np.reshape(hist[:, :, drop_values:], (4, num_fold * (epochs_per_fold - drop_values)))\n",
        "print(\"Mean Validation Accuracy  =\", np.mean(hist[1, :, -drop_values:]))\n",
        "\n",
        "plt.plot(drop_hist[0]); plt.plot(drop_hist[1])\n",
        "plt.legend(['train', 'val'], loc='lower left')"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Validation Accuracy  = 0.04176197819784284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8e515d25f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBTou7CG4a7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "a524730a-da4f-4f09-8ab3-cc7fd0ec6e8c"
      },
      "source": [
        "plt.plot(drop_hist[2]); plt.plot(drop_hist[3])\n",
        "plt.legend(['train', 'val'], loc='upper left')"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8e514f2780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArOMJw1Y4jmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update dataframe with imputed values by averaging results of 5 neural networks \n",
        "data['PE'][np.array(data['PE'].isnull())] = np.mean(Y_test, axis=1)\n",
        "\n",
        "# Write intermediate data to file\n",
        "data.to_csv('/content/gdrive/My Drive/Data/train_test_data_PEfilled.csv', index=False)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGGfOCDy63W5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "16d6bc89-e340-4109-a6e3-ba09b9a12055"
      },
      "source": [
        "# Plot PE of all wells (original plus imputed) \n",
        "plt.plot(data['PE'])"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8e51446ba8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nre-InYMFoE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "92b8b38a-dbd3-4190-d4e0-b098e8f09ec0"
      },
      "source": [
        "data['PE'].isnull().sum() #No missing PE Values "
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVnqHgRv7Emg",
        "colab_type": "text"
      },
      "source": [
        "# Facies Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kygPXXF9PKti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "53a793f0-fd1a-41bd-c0b0-062a40e522a7"
      },
      "source": [
        "file_2 = file.copy()\n",
        "names = file['Well Name'].unique()\n",
        "for name in names:\n",
        "  if name not in ['STUART','CRAWFORD']:\n",
        "    file_2 = file_2[file_2['Well Name'] != name]\n",
        "file_2.shape"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(830, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ0olAiI7EGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "a41ccfdf-d2ad-4c61-a0f8-7572bb83c2f7"
      },
      "source": [
        "file_ii = pd.read_csv('/content/gdrive/My Drive/Data/train_test_data_PEfilled.csv')\n",
        "training_data = pd.concat([file_ii, file_2], axis = 0)\n",
        "print(training_data.shape)\n",
        "training_data.head()"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4979, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Facies</th>\n",
              "      <th>Formation</th>\n",
              "      <th>Well Name</th>\n",
              "      <th>Depth</th>\n",
              "      <th>GR</th>\n",
              "      <th>ILD_log10</th>\n",
              "      <th>DeltaPHI</th>\n",
              "      <th>PHIND</th>\n",
              "      <th>PE</th>\n",
              "      <th>NM_M</th>\n",
              "      <th>RELPOS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2793.0</td>\n",
              "      <td>77.45</td>\n",
              "      <td>0.664</td>\n",
              "      <td>9.9</td>\n",
              "      <td>11.915</td>\n",
              "      <td>4.6</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2793.5</td>\n",
              "      <td>78.26</td>\n",
              "      <td>0.661</td>\n",
              "      <td>14.2</td>\n",
              "      <td>12.565</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2794.0</td>\n",
              "      <td>79.05</td>\n",
              "      <td>0.658</td>\n",
              "      <td>14.8</td>\n",
              "      <td>13.050</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2794.5</td>\n",
              "      <td>86.10</td>\n",
              "      <td>0.655</td>\n",
              "      <td>13.9</td>\n",
              "      <td>13.115</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2795.0</td>\n",
              "      <td>74.58</td>\n",
              "      <td>0.647</td>\n",
              "      <td>13.5</td>\n",
              "      <td>13.300</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.915</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Facies Formation  Well Name   Depth  ...   PHIND   PE  NM_M  RELPOS\n",
              "0       3     A1 SH  SHRIMPLIN  2793.0  ...  11.915  4.6     1   1.000\n",
              "1       3     A1 SH  SHRIMPLIN  2793.5  ...  12.565  4.1     1   0.979\n",
              "2       3     A1 SH  SHRIMPLIN  2794.0  ...  13.050  3.6     1   0.957\n",
              "3       3     A1 SH  SHRIMPLIN  2794.5  ...  13.115  3.5     1   0.936\n",
              "4       3     A1 SH  SHRIMPLIN  2795.0  ...  13.300  3.4     1   0.915\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXt0dEpIonjG",
        "colab_type": "text"
      },
      "source": [
        "## Data Wrangling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz1VLKg1oHy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set_option(\"display.max_rows\", 10)\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "training_data['Well Name'] = training_data['Well Name'].astype('category')\n",
        "training_data['Formation'] = training_data['Formation'].astype('category')\n",
        "training_data['Well Name'].unique()\n",
        "\n",
        "# 1=sandstone  2=c_siltstone   3=f_siltstone \n",
        "# 4=marine_silt_shale 5=mudstone 6=wackestone 7=dolomite\n",
        "# 8=packstone 9=bafflestone\n",
        "\n",
        "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00',\n",
        "       '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
        "\n",
        "facies_labels = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS','WS', 'D','PS', 'BS']\n",
        "#facies_color_map is a dictionary that maps facies labels\n",
        "#to their respective colors\n",
        "facies_color_map = {}\n",
        "for ind, label in enumerate(facies_labels):\n",
        "    facies_color_map[label] = facies_colors[ind]\n",
        "  #mapping facies labels to the dataframe\n",
        "training_data.loc[:,'FaciesLabels'] = training_data.apply(lambda row: label_facies(row, facies_labels), axis=1)\n",
        "\n",
        "correct_facies_labels = training_data['Facies'].values\n",
        "feature_vectors = training_data.drop(['Formation', 'FaciesLabels', 'Facies','Well Name'], axis=1) #, 'RELPOS', 'NM_M', 'Depth', 'ILD_log10',  'DeltaPHI',   'PHIND'], axis=1)\n",
        "\n",
        "well_labels = training_data[['Well Name', 'Facies']].values\n",
        "well_name = training_data['Well Name'].values\n",
        "depth = training_data['Depth'].values\n"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evBkBJDlUmEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "7edb9a7e-f077-436e-c5f7-3069bdb036fc"
      },
      "source": [
        "training_data[:3]"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Facies</th>\n",
              "      <th>Formation</th>\n",
              "      <th>Well Name</th>\n",
              "      <th>Depth</th>\n",
              "      <th>GR</th>\n",
              "      <th>ILD_log10</th>\n",
              "      <th>DeltaPHI</th>\n",
              "      <th>PHIND</th>\n",
              "      <th>PE</th>\n",
              "      <th>NM_M</th>\n",
              "      <th>RELPOS</th>\n",
              "      <th>FaciesLabels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2793.0</td>\n",
              "      <td>77.45</td>\n",
              "      <td>0.664</td>\n",
              "      <td>9.9</td>\n",
              "      <td>11.915</td>\n",
              "      <td>4.6</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000</td>\n",
              "      <td>FSiS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2793.5</td>\n",
              "      <td>78.26</td>\n",
              "      <td>0.661</td>\n",
              "      <td>14.2</td>\n",
              "      <td>12.565</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.979</td>\n",
              "      <td>FSiS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>A1 SH</td>\n",
              "      <td>SHRIMPLIN</td>\n",
              "      <td>2794.0</td>\n",
              "      <td>79.05</td>\n",
              "      <td>0.658</td>\n",
              "      <td>14.8</td>\n",
              "      <td>13.050</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.957</td>\n",
              "      <td>FSiS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Facies Formation  Well Name   Depth  ...   PE  NM_M  RELPOS  FaciesLabels\n",
              "0       3     A1 SH  SHRIMPLIN  2793.0  ...  4.6     1   1.000          FSiS\n",
              "1       3     A1 SH  SHRIMPLIN  2793.5  ...  4.1     1   0.979          FSiS\n",
              "2       3     A1 SH  SHRIMPLIN  2794.0  ...  3.6     1   0.957          FSiS\n",
              "\n",
              "[3 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klWWxFlHo8Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "scaler = preprocessing.StandardScaler().fit(feature_vectors)\n",
        "scaled_features = scaler.transform(feature_vectors)\n",
        "\n",
        "data_out = np.hstack([well_labels, scaled_features])"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmXfuDrVpcD1",
        "colab_type": "text"
      },
      "source": [
        "# Data Transform\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvIQHHE_pWyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "924d7c7c-9472-4e13-ff38-03675c02d2b8"
      },
      "source": [
        "data = data_out\n",
        "well_data = {}\n",
        "well_names = list(set(data[:, 0])) #set of well names\n",
        "for name in well_names:\n",
        "    well_data[name] = [[], []] #creates a dictionary containing list of list for the well names\n",
        "    \n",
        "for row in data:\n",
        "    well_data[row[0]][1].append(row[1]) #Append facies to the second list[]\n",
        "    well_data[row[0]][0].append(list(row[2::])) #Append features to the first list[]\n",
        "\n",
        "#For data padding\n",
        "positive_lag = 10\n",
        "negative_lag = 11\n",
        "\n",
        "chunks_cnn = []\n",
        "chunks_cnn_test = []\n",
        "chunk_length = positive_lag+negative_lag+1 #were gonna predict middle facies\n",
        "chunks_facies_cnn = []\n",
        "\n",
        "for name in well_names:\n",
        "    if name not in ['STUART', 'CRAWFORD']:  #Training set augumentation\n",
        "        test_well_data = well_data[name]    #Returns a list of list\n",
        "        log_values = np.array(test_well_data[0]) #values\n",
        "        log_values_padded = np.lib.pad(log_values, (negative_lag,positive_lag), 'edge')[:, negative_lag:-positive_lag] #Pad values(11,10) and \n",
        "                                                                                        #returns index from 11:-10\n",
        "        facies_values =  np.array(test_well_data[1])\n",
        "        for i in range(log_values.shape[0]):\n",
        "            chunk = log_values_padded[i:i+chunk_length, :]\n",
        "            chunk_trans = chunk.T\n",
        "            chunks_cnn.append(chunk_trans)\n",
        "            chunks_facies_cnn.append(facies_values[i])\n",
        "    else:\n",
        "        test_well_data = well_data[name]\n",
        "        log_values = np.array(test_well_data[0])\n",
        "        log_values_padded = np.lib.pad(log_values, (negative_lag,positive_lag), 'edge')[:, negative_lag:-positive_lag]\n",
        "        facies_values =  np.array(test_well_data[1])\n",
        "        for i in range(log_values.shape[0]):\n",
        "            chunk = log_values_padded[i:i+chunk_length, :]\n",
        "            chunk_trans = chunk.T\n",
        "            chunks_cnn_test.append(chunk_trans)\n",
        "\n",
        "chunks_cnn = np.array(chunks_cnn)\n",
        "chunks_cnn_test = np.array(chunks_cnn_test)\n",
        "\n",
        "chunks_facies_cnn = np.array(chunks_facies_cnn, dtype=np.int32)-1\n",
        "\n",
        "unique_facies = len(set(chunks_facies_cnn))\n",
        "print (unique_facies, set(chunks_facies_cnn))\n",
        "print (chunks_cnn.shape, chunks_cnn_test.shape)\n",
        "print (chunks_facies_cnn.shape, chunks_cnn_test.shape)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 {0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
            "(4149, 8, 22) (830, 8, 22)\n",
            "(4149,) (830, 8, 22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqv7TtOKvGKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = chunks_cnn #Save data to X and Y for training\n",
        "y = chunks_facies_cnn\n",
        "\n",
        "X = X.reshape((chunks_cnn.shape[0], chunks_cnn.shape[1], chunks_cnn.shape[2], 1))\n",
        "\n",
        "y = np_utils.to_categorical(y)"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_f4mnJlvKvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 128\n",
        "cnnet = Sequential()\n",
        "cnnet.add(Convolution2D(N, 1, 5, border_mode=\"same\",activation=\"relu\",input_shape=(chunks_cnn.shape[1], chunks_cnn.shape[2], 1)))\n",
        "cnnet.add(MaxPooling2D(pool_size=(1, 2)))\n",
        "cnnet.add(Dropout(0.25))\n",
        "cnnet.add(Convolution2D(N, 1, 3, border_mode=\"same\",activation=\"relu\",input_shape=(chunks_cnn.shape[1], chunks_cnn.shape[2], 1)))\n",
        "cnnet.add(MaxPooling2D(pool_size=(1, 2)))\n",
        "#cnn.add(Dropout(0.5))\n",
        "cnnet.add(Convolution2D(N, 2, 2, border_mode=\"same\", activation=\"relu\"))\n",
        "#cnn.add(Convolution2D(N, 3, 1, border_mode=\"same\", activation=\"relu\"))\n",
        "cnnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnnet.add(Dropout(0.8))\n",
        "cnnet.add(Flatten())\n",
        "cnnet.add(Dense(128, activation=\"relu\"))\n",
        "cnnet.add(Dropout(0.5))\n",
        "cnnet.add(Dense(64, activation=\"relu\"))\n",
        "cnnet.add(Dropout(0.5))\n",
        "cnnet.add(Dense(9, activation=\"softmax\"))\n",
        "cnnet.compile(loss=\"categorical_crossentropy\", optimizer=\"Adamax\", metrics=['acc'])"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mXS6IFpHsw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "outputId": "3f7cfabf-fcf9-4d86-df8d-3f4ea656bc92"
      },
      "source": [
        "cnnet.summary()\n",
        "intial_weights_ii = cnnet.get_weights()"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_31 (Conv2D)           (None, 8, 22, 128)        768       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 8, 11, 128)        0         \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 8, 11, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 8, 11, 128)        49280     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 8, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 8, 5, 128)         65664     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 4, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 4, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 9)                 585       \n",
            "=================================================================\n",
            "Total params: 255,753\n",
            "Trainable params: 255,753\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_gP144rvN4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "763dafa5-625d-452a-9430-0d2d94e63587"
      },
      "source": [
        "cnnet_hist = History()\n",
        "epoch_fold = 200\n",
        "hist = np.zeros((4, 1, epoch_fold))\n",
        "start = time.time()\n",
        "cnnet.fit(X, y, nb_epoch=epoch_fold, validation_split=0.25, batch_size=64, verbose=1, shuffle=True, callbacks=[cnnet_hist])\n",
        "hist[:,0,:] = [cnnet_hist.history['acc'], cnnet_hist.history['val_acc'], cnnet_hist.history['loss'], cnnet_hist.history['val_loss']]\n",
        "print(f'Time to train Network {time.time() - start}')"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4786 - acc: 0.8187 - val_loss: 1.7275 - val_acc: 0.4961\n",
            "Epoch 6/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4723 - acc: 0.8267 - val_loss: 1.6959 - val_acc: 0.5058\n",
            "Epoch 7/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4915 - acc: 0.8187 - val_loss: 1.6783 - val_acc: 0.4913\n",
            "Epoch 8/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4533 - acc: 0.8296 - val_loss: 1.7583 - val_acc: 0.4961\n",
            "Epoch 9/500\n",
            "3111/3111 [==============================] - 5s 2ms/step - loss: 0.4797 - acc: 0.8235 - val_loss: 1.6595 - val_acc: 0.4817\n",
            "Epoch 10/500\n",
            "3111/3111 [==============================] - 8s 3ms/step - loss: 0.4731 - acc: 0.8274 - val_loss: 1.6468 - val_acc: 0.5000\n",
            "Epoch 11/500\n",
            "3111/3111 [==============================] - 5s 2ms/step - loss: 0.4784 - acc: 0.8290 - val_loss: 1.6173 - val_acc: 0.5039\n",
            "Epoch 12/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4648 - acc: 0.8284 - val_loss: 1.7937 - val_acc: 0.4933\n",
            "Epoch 13/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4776 - acc: 0.8219 - val_loss: 1.6301 - val_acc: 0.5116\n",
            "Epoch 14/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4589 - acc: 0.8332 - val_loss: 1.6607 - val_acc: 0.5096\n",
            "Epoch 15/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4547 - acc: 0.8316 - val_loss: 1.7114 - val_acc: 0.5067\n",
            "Epoch 16/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4772 - acc: 0.8255 - val_loss: 1.6189 - val_acc: 0.5135\n",
            "Epoch 17/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4569 - acc: 0.8335 - val_loss: 1.6474 - val_acc: 0.5164\n",
            "Epoch 18/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4397 - acc: 0.8412 - val_loss: 1.6607 - val_acc: 0.4990\n",
            "Epoch 19/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.4527 - acc: 0.8309 - val_loss: 1.7279 - val_acc: 0.5183\n",
            "Epoch 20/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4559 - acc: 0.8296 - val_loss: 1.7364 - val_acc: 0.5183\n",
            "Epoch 21/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4519 - acc: 0.8261 - val_loss: 1.7217 - val_acc: 0.5125\n",
            "Epoch 22/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4714 - acc: 0.8255 - val_loss: 1.7727 - val_acc: 0.5135\n",
            "Epoch 23/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4523 - acc: 0.8322 - val_loss: 1.6550 - val_acc: 0.5212\n",
            "Epoch 24/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4614 - acc: 0.8296 - val_loss: 1.7613 - val_acc: 0.5087\n",
            "Epoch 25/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4666 - acc: 0.8309 - val_loss: 1.7033 - val_acc: 0.5058\n",
            "Epoch 26/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4495 - acc: 0.8284 - val_loss: 1.7041 - val_acc: 0.5154\n",
            "Epoch 27/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4479 - acc: 0.8338 - val_loss: 1.6649 - val_acc: 0.5154\n",
            "Epoch 28/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4710 - acc: 0.8345 - val_loss: 1.6917 - val_acc: 0.5096\n",
            "Epoch 29/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.4589 - acc: 0.8280 - val_loss: 1.7560 - val_acc: 0.4981\n",
            "Epoch 30/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4385 - acc: 0.8351 - val_loss: 1.7290 - val_acc: 0.5183\n",
            "Epoch 31/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4587 - acc: 0.8306 - val_loss: 1.6933 - val_acc: 0.5010\n",
            "Epoch 32/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4427 - acc: 0.8409 - val_loss: 1.7412 - val_acc: 0.5096\n",
            "Epoch 33/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4537 - acc: 0.8367 - val_loss: 1.7583 - val_acc: 0.4942\n",
            "Epoch 34/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4466 - acc: 0.8399 - val_loss: 1.7991 - val_acc: 0.4933\n",
            "Epoch 35/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.4293 - acc: 0.8467 - val_loss: 1.6867 - val_acc: 0.4981\n",
            "Epoch 36/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.4577 - acc: 0.8361 - val_loss: 1.6361 - val_acc: 0.5058\n",
            "Epoch 37/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4565 - acc: 0.8335 - val_loss: 1.7380 - val_acc: 0.5048\n",
            "Epoch 38/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4556 - acc: 0.8367 - val_loss: 1.6317 - val_acc: 0.5164\n",
            "Epoch 39/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4536 - acc: 0.8264 - val_loss: 1.7707 - val_acc: 0.5183\n",
            "Epoch 40/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4424 - acc: 0.8300 - val_loss: 1.6743 - val_acc: 0.5135\n",
            "Epoch 41/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4412 - acc: 0.8367 - val_loss: 1.7180 - val_acc: 0.5106\n",
            "Epoch 42/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4440 - acc: 0.8415 - val_loss: 1.7927 - val_acc: 0.5096\n",
            "Epoch 43/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4223 - acc: 0.8435 - val_loss: 1.7312 - val_acc: 0.4952\n",
            "Epoch 44/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4285 - acc: 0.8451 - val_loss: 1.8671 - val_acc: 0.5077\n",
            "Epoch 45/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4334 - acc: 0.8460 - val_loss: 1.7339 - val_acc: 0.4990\n",
            "Epoch 46/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4362 - acc: 0.8364 - val_loss: 1.6940 - val_acc: 0.4942\n",
            "Epoch 47/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4399 - acc: 0.8441 - val_loss: 1.6962 - val_acc: 0.5000\n",
            "Epoch 48/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4282 - acc: 0.8428 - val_loss: 1.7442 - val_acc: 0.5058\n",
            "Epoch 49/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.4423 - acc: 0.8341 - val_loss: 1.6920 - val_acc: 0.4971\n",
            "Epoch 50/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.4421 - acc: 0.8351 - val_loss: 1.7987 - val_acc: 0.5048\n",
            "Epoch 51/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4197 - acc: 0.8441 - val_loss: 1.8055 - val_acc: 0.5193\n",
            "Epoch 52/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4312 - acc: 0.8454 - val_loss: 1.7974 - val_acc: 0.5193\n",
            "Epoch 53/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4262 - acc: 0.8457 - val_loss: 1.8058 - val_acc: 0.5029\n",
            "Epoch 54/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4280 - acc: 0.8425 - val_loss: 1.7499 - val_acc: 0.5154\n",
            "Epoch 55/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4256 - acc: 0.8370 - val_loss: 1.7620 - val_acc: 0.5019\n",
            "Epoch 56/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4330 - acc: 0.8435 - val_loss: 1.7725 - val_acc: 0.5145\n",
            "Epoch 57/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4119 - acc: 0.8505 - val_loss: 1.7849 - val_acc: 0.5125\n",
            "Epoch 58/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4367 - acc: 0.8422 - val_loss: 1.7674 - val_acc: 0.5154\n",
            "Epoch 59/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4321 - acc: 0.8464 - val_loss: 1.7075 - val_acc: 0.5212\n",
            "Epoch 60/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4149 - acc: 0.8550 - val_loss: 1.7659 - val_acc: 0.5260\n",
            "Epoch 61/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4245 - acc: 0.8476 - val_loss: 1.7361 - val_acc: 0.5145\n",
            "Epoch 62/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4200 - acc: 0.8422 - val_loss: 1.7543 - val_acc: 0.5183\n",
            "Epoch 63/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4187 - acc: 0.8444 - val_loss: 1.8295 - val_acc: 0.5019\n",
            "Epoch 64/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4073 - acc: 0.8428 - val_loss: 1.7439 - val_acc: 0.5096\n",
            "Epoch 65/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4051 - acc: 0.8537 - val_loss: 1.8925 - val_acc: 0.4952\n",
            "Epoch 66/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4337 - acc: 0.8419 - val_loss: 1.7331 - val_acc: 0.5145\n",
            "Epoch 67/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4280 - acc: 0.8483 - val_loss: 1.7302 - val_acc: 0.5164\n",
            "Epoch 68/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4187 - acc: 0.8451 - val_loss: 1.7625 - val_acc: 0.5029\n",
            "Epoch 69/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4240 - acc: 0.8447 - val_loss: 1.8196 - val_acc: 0.5154\n",
            "Epoch 70/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4295 - acc: 0.8512 - val_loss: 1.8178 - val_acc: 0.5019\n",
            "Epoch 71/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3977 - acc: 0.8586 - val_loss: 1.8558 - val_acc: 0.5173\n",
            "Epoch 72/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4237 - acc: 0.8476 - val_loss: 1.8802 - val_acc: 0.4942\n",
            "Epoch 73/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4470 - acc: 0.8374 - val_loss: 1.7490 - val_acc: 0.5058\n",
            "Epoch 74/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4281 - acc: 0.8521 - val_loss: 1.8985 - val_acc: 0.4904\n",
            "Epoch 75/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4125 - acc: 0.8441 - val_loss: 1.7070 - val_acc: 0.5010\n",
            "Epoch 76/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4094 - acc: 0.8505 - val_loss: 1.7875 - val_acc: 0.5077\n",
            "Epoch 77/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4143 - acc: 0.8534 - val_loss: 1.7937 - val_acc: 0.5010\n",
            "Epoch 78/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4067 - acc: 0.8528 - val_loss: 1.7562 - val_acc: 0.5154\n",
            "Epoch 79/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4070 - acc: 0.8502 - val_loss: 1.7635 - val_acc: 0.5183\n",
            "Epoch 80/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4064 - acc: 0.8521 - val_loss: 1.7921 - val_acc: 0.5067\n",
            "Epoch 81/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4058 - acc: 0.8451 - val_loss: 1.8394 - val_acc: 0.5231\n",
            "Epoch 82/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3924 - acc: 0.8489 - val_loss: 1.7664 - val_acc: 0.5173\n",
            "Epoch 83/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4025 - acc: 0.8576 - val_loss: 1.8142 - val_acc: 0.5202\n",
            "Epoch 84/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4059 - acc: 0.8563 - val_loss: 1.7735 - val_acc: 0.5145\n",
            "Epoch 85/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3990 - acc: 0.8531 - val_loss: 1.7948 - val_acc: 0.5202\n",
            "Epoch 86/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4083 - acc: 0.8541 - val_loss: 1.8980 - val_acc: 0.5048\n",
            "Epoch 87/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4071 - acc: 0.8428 - val_loss: 1.8035 - val_acc: 0.5328\n",
            "Epoch 88/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3947 - acc: 0.8515 - val_loss: 1.8261 - val_acc: 0.5202\n",
            "Epoch 89/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3621 - acc: 0.8647 - val_loss: 1.7729 - val_acc: 0.5116\n",
            "Epoch 90/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3898 - acc: 0.8560 - val_loss: 1.8056 - val_acc: 0.5019\n",
            "Epoch 91/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3962 - acc: 0.8547 - val_loss: 1.7622 - val_acc: 0.5202\n",
            "Epoch 92/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3967 - acc: 0.8544 - val_loss: 1.7578 - val_acc: 0.5154\n",
            "Epoch 93/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3948 - acc: 0.8592 - val_loss: 1.8836 - val_acc: 0.5010\n",
            "Epoch 94/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4165 - acc: 0.8492 - val_loss: 1.7839 - val_acc: 0.5145\n",
            "Epoch 95/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4147 - acc: 0.8441 - val_loss: 1.7618 - val_acc: 0.5328\n",
            "Epoch 96/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4063 - acc: 0.8566 - val_loss: 1.8237 - val_acc: 0.5087\n",
            "Epoch 97/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4043 - acc: 0.8576 - val_loss: 1.8561 - val_acc: 0.4981\n",
            "Epoch 98/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3860 - acc: 0.8579 - val_loss: 1.8118 - val_acc: 0.5154\n",
            "Epoch 99/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3994 - acc: 0.8570 - val_loss: 1.8606 - val_acc: 0.5029\n",
            "Epoch 100/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3954 - acc: 0.8592 - val_loss: 1.8613 - val_acc: 0.5106\n",
            "Epoch 101/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4120 - acc: 0.8515 - val_loss: 1.7826 - val_acc: 0.5019\n",
            "Epoch 102/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3937 - acc: 0.8599 - val_loss: 1.8006 - val_acc: 0.4933\n",
            "Epoch 103/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3792 - acc: 0.8663 - val_loss: 1.7924 - val_acc: 0.5145\n",
            "Epoch 104/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3938 - acc: 0.8544 - val_loss: 1.7891 - val_acc: 0.5106\n",
            "Epoch 105/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3941 - acc: 0.8640 - val_loss: 1.8384 - val_acc: 0.5125\n",
            "Epoch 106/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3790 - acc: 0.8586 - val_loss: 1.8555 - val_acc: 0.5125\n",
            "Epoch 107/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3854 - acc: 0.8579 - val_loss: 1.9200 - val_acc: 0.5010\n",
            "Epoch 108/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3716 - acc: 0.8647 - val_loss: 1.9091 - val_acc: 0.5096\n",
            "Epoch 109/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3781 - acc: 0.8599 - val_loss: 1.8300 - val_acc: 0.5231\n",
            "Epoch 110/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4114 - acc: 0.8512 - val_loss: 1.9092 - val_acc: 0.5058\n",
            "Epoch 111/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3811 - acc: 0.8640 - val_loss: 1.8317 - val_acc: 0.5116\n",
            "Epoch 112/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4195 - acc: 0.8435 - val_loss: 1.8152 - val_acc: 0.5116\n",
            "Epoch 113/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3720 - acc: 0.8640 - val_loss: 1.8774 - val_acc: 0.4913\n",
            "Epoch 114/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3904 - acc: 0.8557 - val_loss: 1.8086 - val_acc: 0.5048\n",
            "Epoch 115/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3954 - acc: 0.8492 - val_loss: 1.8927 - val_acc: 0.5087\n",
            "Epoch 116/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3688 - acc: 0.8631 - val_loss: 1.7387 - val_acc: 0.5106\n",
            "Epoch 117/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3840 - acc: 0.8560 - val_loss: 1.8665 - val_acc: 0.5154\n",
            "Epoch 118/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3904 - acc: 0.8531 - val_loss: 1.9087 - val_acc: 0.5067\n",
            "Epoch 119/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3742 - acc: 0.8692 - val_loss: 1.9120 - val_acc: 0.4942\n",
            "Epoch 120/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3601 - acc: 0.8740 - val_loss: 1.9344 - val_acc: 0.4952\n",
            "Epoch 121/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3925 - acc: 0.8560 - val_loss: 1.8119 - val_acc: 0.4990\n",
            "Epoch 122/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3878 - acc: 0.8573 - val_loss: 1.8274 - val_acc: 0.4990\n",
            "Epoch 123/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3968 - acc: 0.8566 - val_loss: 1.8693 - val_acc: 0.5039\n",
            "Epoch 124/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3871 - acc: 0.8647 - val_loss: 1.8187 - val_acc: 0.5154\n",
            "Epoch 125/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3755 - acc: 0.8599 - val_loss: 1.8987 - val_acc: 0.5154\n",
            "Epoch 126/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3714 - acc: 0.8676 - val_loss: 1.9425 - val_acc: 0.4913\n",
            "Epoch 127/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3901 - acc: 0.8595 - val_loss: 1.8731 - val_acc: 0.5096\n",
            "Epoch 128/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3730 - acc: 0.8669 - val_loss: 1.9685 - val_acc: 0.4913\n",
            "Epoch 129/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3573 - acc: 0.8734 - val_loss: 1.8159 - val_acc: 0.5077\n",
            "Epoch 130/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3842 - acc: 0.8537 - val_loss: 1.8841 - val_acc: 0.5193\n",
            "Epoch 131/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3642 - acc: 0.8679 - val_loss: 1.9421 - val_acc: 0.5212\n",
            "Epoch 132/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.4080 - acc: 0.8528 - val_loss: 1.8771 - val_acc: 0.5164\n",
            "Epoch 133/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3892 - acc: 0.8627 - val_loss: 1.8680 - val_acc: 0.4981\n",
            "Epoch 134/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3899 - acc: 0.8573 - val_loss: 1.8697 - val_acc: 0.5058\n",
            "Epoch 135/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3657 - acc: 0.8705 - val_loss: 1.8491 - val_acc: 0.5337\n",
            "Epoch 136/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3548 - acc: 0.8672 - val_loss: 1.9148 - val_acc: 0.5212\n",
            "Epoch 137/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3836 - acc: 0.8579 - val_loss: 1.8944 - val_acc: 0.5231\n",
            "Epoch 138/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3738 - acc: 0.8660 - val_loss: 1.8657 - val_acc: 0.5366\n",
            "Epoch 139/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3524 - acc: 0.8644 - val_loss: 2.0015 - val_acc: 0.5173\n",
            "Epoch 140/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3570 - acc: 0.8734 - val_loss: 1.8742 - val_acc: 0.5145\n",
            "Epoch 141/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3694 - acc: 0.8666 - val_loss: 1.9064 - val_acc: 0.5087\n",
            "Epoch 142/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3677 - acc: 0.8660 - val_loss: 1.8014 - val_acc: 0.5173\n",
            "Epoch 143/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3653 - acc: 0.8698 - val_loss: 1.9108 - val_acc: 0.5173\n",
            "Epoch 144/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3567 - acc: 0.8615 - val_loss: 1.8665 - val_acc: 0.5077\n",
            "Epoch 145/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3648 - acc: 0.8663 - val_loss: 1.8803 - val_acc: 0.5135\n",
            "Epoch 146/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3645 - acc: 0.8631 - val_loss: 1.9528 - val_acc: 0.5231\n",
            "Epoch 147/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3794 - acc: 0.8621 - val_loss: 1.8982 - val_acc: 0.5048\n",
            "Epoch 148/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3607 - acc: 0.8615 - val_loss: 1.8214 - val_acc: 0.5077\n",
            "Epoch 149/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3652 - acc: 0.8663 - val_loss: 1.8430 - val_acc: 0.4961\n",
            "Epoch 150/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3823 - acc: 0.8579 - val_loss: 1.8738 - val_acc: 0.5048\n",
            "Epoch 151/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3513 - acc: 0.8705 - val_loss: 1.9344 - val_acc: 0.5193\n",
            "Epoch 152/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3490 - acc: 0.8660 - val_loss: 1.9125 - val_acc: 0.5077\n",
            "Epoch 153/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3606 - acc: 0.8705 - val_loss: 1.8249 - val_acc: 0.5125\n",
            "Epoch 154/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3675 - acc: 0.8708 - val_loss: 1.8794 - val_acc: 0.5222\n",
            "Epoch 155/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3559 - acc: 0.8653 - val_loss: 1.9322 - val_acc: 0.5154\n",
            "Epoch 156/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3805 - acc: 0.8615 - val_loss: 1.9513 - val_acc: 0.5039\n",
            "Epoch 157/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3606 - acc: 0.8708 - val_loss: 1.9857 - val_acc: 0.5029\n",
            "Epoch 158/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3595 - acc: 0.8740 - val_loss: 1.9416 - val_acc: 0.5087\n",
            "Epoch 159/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3729 - acc: 0.8602 - val_loss: 1.8985 - val_acc: 0.4933\n",
            "Epoch 160/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3616 - acc: 0.8746 - val_loss: 1.9736 - val_acc: 0.5145\n",
            "Epoch 161/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3519 - acc: 0.8701 - val_loss: 1.8871 - val_acc: 0.5202\n",
            "Epoch 162/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3666 - acc: 0.8714 - val_loss: 1.9010 - val_acc: 0.5202\n",
            "Epoch 163/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3506 - acc: 0.8730 - val_loss: 1.9531 - val_acc: 0.5048\n",
            "Epoch 164/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3715 - acc: 0.8647 - val_loss: 1.9084 - val_acc: 0.5173\n",
            "Epoch 165/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3591 - acc: 0.8711 - val_loss: 1.9716 - val_acc: 0.5077\n",
            "Epoch 166/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3549 - acc: 0.8695 - val_loss: 1.8981 - val_acc: 0.5077\n",
            "Epoch 167/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3632 - acc: 0.8663 - val_loss: 1.9378 - val_acc: 0.5106\n",
            "Epoch 168/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3570 - acc: 0.8705 - val_loss: 2.0088 - val_acc: 0.5154\n",
            "Epoch 169/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3403 - acc: 0.8801 - val_loss: 2.0537 - val_acc: 0.4971\n",
            "Epoch 170/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3493 - acc: 0.8795 - val_loss: 1.9531 - val_acc: 0.5039\n",
            "Epoch 171/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3492 - acc: 0.8717 - val_loss: 1.9333 - val_acc: 0.5135\n",
            "Epoch 172/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3384 - acc: 0.8772 - val_loss: 1.8522 - val_acc: 0.5279\n",
            "Epoch 173/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3745 - acc: 0.8608 - val_loss: 1.8836 - val_acc: 0.5202\n",
            "Epoch 174/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3257 - acc: 0.8788 - val_loss: 1.9081 - val_acc: 0.5039\n",
            "Epoch 175/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3438 - acc: 0.8795 - val_loss: 1.9444 - val_acc: 0.5048\n",
            "Epoch 176/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3523 - acc: 0.8734 - val_loss: 1.9749 - val_acc: 0.5173\n",
            "Epoch 177/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3535 - acc: 0.8746 - val_loss: 1.9782 - val_acc: 0.5212\n",
            "Epoch 178/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3667 - acc: 0.8689 - val_loss: 1.9386 - val_acc: 0.5058\n",
            "Epoch 179/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3310 - acc: 0.8830 - val_loss: 1.8742 - val_acc: 0.5154\n",
            "Epoch 180/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3398 - acc: 0.8824 - val_loss: 1.8933 - val_acc: 0.5279\n",
            "Epoch 181/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3455 - acc: 0.8772 - val_loss: 1.9324 - val_acc: 0.5145\n",
            "Epoch 182/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3494 - acc: 0.8750 - val_loss: 1.9334 - val_acc: 0.5067\n",
            "Epoch 183/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3591 - acc: 0.8695 - val_loss: 1.8868 - val_acc: 0.5241\n",
            "Epoch 184/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3358 - acc: 0.8756 - val_loss: 1.9893 - val_acc: 0.5077\n",
            "Epoch 185/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3436 - acc: 0.8769 - val_loss: 2.0030 - val_acc: 0.5048\n",
            "Epoch 186/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3237 - acc: 0.8798 - val_loss: 1.9490 - val_acc: 0.5164\n",
            "Epoch 187/500\n",
            "3111/3111 [==============================] - 5s 2ms/step - loss: 0.3379 - acc: 0.8807 - val_loss: 1.9622 - val_acc: 0.5125\n",
            "Epoch 188/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3477 - acc: 0.8798 - val_loss: 1.9418 - val_acc: 0.5096\n",
            "Epoch 189/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3504 - acc: 0.8743 - val_loss: 1.9765 - val_acc: 0.5164\n",
            "Epoch 190/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3454 - acc: 0.8737 - val_loss: 1.8622 - val_acc: 0.5250\n",
            "Epoch 191/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3429 - acc: 0.8779 - val_loss: 1.9402 - val_acc: 0.5077\n",
            "Epoch 192/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3362 - acc: 0.8824 - val_loss: 1.9057 - val_acc: 0.5193\n",
            "Epoch 193/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3448 - acc: 0.8820 - val_loss: 1.9819 - val_acc: 0.5231\n",
            "Epoch 194/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3493 - acc: 0.8721 - val_loss: 1.9864 - val_acc: 0.5222\n",
            "Epoch 195/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3517 - acc: 0.8801 - val_loss: 1.9141 - val_acc: 0.5164\n",
            "Epoch 196/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3426 - acc: 0.8785 - val_loss: 2.0205 - val_acc: 0.5212\n",
            "Epoch 197/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3560 - acc: 0.8660 - val_loss: 2.0106 - val_acc: 0.5019\n",
            "Epoch 198/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3498 - acc: 0.8679 - val_loss: 1.9825 - val_acc: 0.5087\n",
            "Epoch 199/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3501 - acc: 0.8701 - val_loss: 1.9578 - val_acc: 0.5125\n",
            "Epoch 200/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3273 - acc: 0.8788 - val_loss: 2.0434 - val_acc: 0.5077\n",
            "Epoch 201/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3552 - acc: 0.8740 - val_loss: 1.9544 - val_acc: 0.5241\n",
            "Epoch 202/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3338 - acc: 0.8827 - val_loss: 2.0157 - val_acc: 0.5077\n",
            "Epoch 203/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3236 - acc: 0.8878 - val_loss: 1.9726 - val_acc: 0.5164\n",
            "Epoch 204/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3209 - acc: 0.8772 - val_loss: 2.0164 - val_acc: 0.5019\n",
            "Epoch 205/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3292 - acc: 0.8791 - val_loss: 2.0774 - val_acc: 0.5241\n",
            "Epoch 206/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3361 - acc: 0.8737 - val_loss: 1.9599 - val_acc: 0.5193\n",
            "Epoch 207/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3264 - acc: 0.8846 - val_loss: 2.1015 - val_acc: 0.5029\n",
            "Epoch 208/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3361 - acc: 0.8766 - val_loss: 1.9601 - val_acc: 0.5193\n",
            "Epoch 209/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3529 - acc: 0.8750 - val_loss: 1.9519 - val_acc: 0.5135\n",
            "Epoch 210/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3375 - acc: 0.8740 - val_loss: 1.9610 - val_acc: 0.5366\n",
            "Epoch 211/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3370 - acc: 0.8801 - val_loss: 1.9813 - val_acc: 0.5222\n",
            "Epoch 212/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3366 - acc: 0.8708 - val_loss: 1.9577 - val_acc: 0.5202\n",
            "Epoch 213/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3332 - acc: 0.8791 - val_loss: 1.9682 - val_acc: 0.5279\n",
            "Epoch 214/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3249 - acc: 0.8824 - val_loss: 1.9387 - val_acc: 0.5260\n",
            "Epoch 215/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3264 - acc: 0.8769 - val_loss: 2.0656 - val_acc: 0.5077\n",
            "Epoch 216/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3450 - acc: 0.8775 - val_loss: 1.9044 - val_acc: 0.5270\n",
            "Epoch 217/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3437 - acc: 0.8753 - val_loss: 1.9685 - val_acc: 0.5202\n",
            "Epoch 218/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3387 - acc: 0.8833 - val_loss: 2.0015 - val_acc: 0.5145\n",
            "Epoch 219/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3345 - acc: 0.8827 - val_loss: 1.9928 - val_acc: 0.5154\n",
            "Epoch 220/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3559 - acc: 0.8714 - val_loss: 2.1096 - val_acc: 0.4990\n",
            "Epoch 221/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3392 - acc: 0.8833 - val_loss: 2.0132 - val_acc: 0.5087\n",
            "Epoch 222/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3190 - acc: 0.8852 - val_loss: 1.9482 - val_acc: 0.5212\n",
            "Epoch 223/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3172 - acc: 0.8885 - val_loss: 2.0083 - val_acc: 0.5202\n",
            "Epoch 224/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3033 - acc: 0.8917 - val_loss: 2.0054 - val_acc: 0.5154\n",
            "Epoch 225/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3289 - acc: 0.8862 - val_loss: 1.9904 - val_acc: 0.5318\n",
            "Epoch 226/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3342 - acc: 0.8766 - val_loss: 1.9429 - val_acc: 0.5135\n",
            "Epoch 227/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3436 - acc: 0.8775 - val_loss: 1.9593 - val_acc: 0.5289\n",
            "Epoch 228/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3194 - acc: 0.8827 - val_loss: 2.0639 - val_acc: 0.5125\n",
            "Epoch 229/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3218 - acc: 0.8865 - val_loss: 2.0195 - val_acc: 0.5183\n",
            "Epoch 230/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3404 - acc: 0.8852 - val_loss: 1.9215 - val_acc: 0.5096\n",
            "Epoch 231/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3451 - acc: 0.8737 - val_loss: 2.0021 - val_acc: 0.5077\n",
            "Epoch 232/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3271 - acc: 0.8872 - val_loss: 1.9568 - val_acc: 0.5222\n",
            "Epoch 233/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3159 - acc: 0.8814 - val_loss: 1.9562 - val_acc: 0.5077\n",
            "Epoch 234/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3293 - acc: 0.8840 - val_loss: 2.0104 - val_acc: 0.5116\n",
            "Epoch 235/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3442 - acc: 0.8798 - val_loss: 1.9100 - val_acc: 0.5250\n",
            "Epoch 236/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3359 - acc: 0.8779 - val_loss: 1.9501 - val_acc: 0.5241\n",
            "Epoch 237/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3235 - acc: 0.8862 - val_loss: 1.9288 - val_acc: 0.5270\n",
            "Epoch 238/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3383 - acc: 0.8827 - val_loss: 2.0388 - val_acc: 0.5077\n",
            "Epoch 239/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3213 - acc: 0.8891 - val_loss: 2.0611 - val_acc: 0.5096\n",
            "Epoch 240/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3067 - acc: 0.8930 - val_loss: 2.0167 - val_acc: 0.5058\n",
            "Epoch 241/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3159 - acc: 0.8849 - val_loss: 1.9468 - val_acc: 0.5096\n",
            "Epoch 242/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3100 - acc: 0.8891 - val_loss: 1.9778 - val_acc: 0.5154\n",
            "Epoch 243/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3107 - acc: 0.8814 - val_loss: 1.9724 - val_acc: 0.5106\n",
            "Epoch 244/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3280 - acc: 0.8830 - val_loss: 2.0378 - val_acc: 0.5193\n",
            "Epoch 245/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3239 - acc: 0.8827 - val_loss: 1.8972 - val_acc: 0.5067\n",
            "Epoch 246/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3012 - acc: 0.8914 - val_loss: 2.0844 - val_acc: 0.5164\n",
            "Epoch 247/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3020 - acc: 0.8939 - val_loss: 1.9564 - val_acc: 0.5135\n",
            "Epoch 248/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3227 - acc: 0.8846 - val_loss: 2.0166 - val_acc: 0.5250\n",
            "Epoch 249/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3529 - acc: 0.8727 - val_loss: 1.9659 - val_acc: 0.5145\n",
            "Epoch 250/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3322 - acc: 0.8788 - val_loss: 1.9798 - val_acc: 0.5222\n",
            "Epoch 251/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3264 - acc: 0.8807 - val_loss: 2.1669 - val_acc: 0.5145\n",
            "Epoch 252/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3241 - acc: 0.8824 - val_loss: 1.9283 - val_acc: 0.5308\n",
            "Epoch 253/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3182 - acc: 0.8891 - val_loss: 2.0218 - val_acc: 0.5154\n",
            "Epoch 254/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3220 - acc: 0.8885 - val_loss: 1.9893 - val_acc: 0.5241\n",
            "Epoch 255/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2888 - acc: 0.8987 - val_loss: 1.9443 - val_acc: 0.5299\n",
            "Epoch 256/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3060 - acc: 0.8968 - val_loss: 1.9931 - val_acc: 0.5154\n",
            "Epoch 257/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3151 - acc: 0.8869 - val_loss: 2.0251 - val_acc: 0.5135\n",
            "Epoch 258/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3058 - acc: 0.8852 - val_loss: 2.1971 - val_acc: 0.5125\n",
            "Epoch 259/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3171 - acc: 0.8875 - val_loss: 2.0786 - val_acc: 0.5250\n",
            "Epoch 260/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3073 - acc: 0.8897 - val_loss: 2.0855 - val_acc: 0.5145\n",
            "Epoch 261/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3348 - acc: 0.8846 - val_loss: 1.9436 - val_acc: 0.5154\n",
            "Epoch 262/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3097 - acc: 0.8885 - val_loss: 2.0914 - val_acc: 0.5212\n",
            "Epoch 263/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3181 - acc: 0.8804 - val_loss: 2.0106 - val_acc: 0.5039\n",
            "Epoch 264/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3309 - acc: 0.8856 - val_loss: 2.0641 - val_acc: 0.5154\n",
            "Epoch 265/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2941 - acc: 0.8930 - val_loss: 2.1324 - val_acc: 0.5106\n",
            "Epoch 266/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2936 - acc: 0.8955 - val_loss: 2.0009 - val_acc: 0.5212\n",
            "Epoch 267/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3090 - acc: 0.8894 - val_loss: 2.0062 - val_acc: 0.5270\n",
            "Epoch 268/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3192 - acc: 0.8875 - val_loss: 2.0151 - val_acc: 0.5087\n",
            "Epoch 269/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3304 - acc: 0.8785 - val_loss: 1.9955 - val_acc: 0.5135\n",
            "Epoch 270/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3280 - acc: 0.8846 - val_loss: 1.8756 - val_acc: 0.5308\n",
            "Epoch 271/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2932 - acc: 0.9000 - val_loss: 1.9993 - val_acc: 0.5222\n",
            "Epoch 272/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2988 - acc: 0.8891 - val_loss: 2.0099 - val_acc: 0.5164\n",
            "Epoch 273/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3333 - acc: 0.8756 - val_loss: 2.0317 - val_acc: 0.5202\n",
            "Epoch 274/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3060 - acc: 0.8926 - val_loss: 2.0479 - val_acc: 0.5135\n",
            "Epoch 275/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3080 - acc: 0.8923 - val_loss: 2.0101 - val_acc: 0.5135\n",
            "Epoch 276/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3174 - acc: 0.8843 - val_loss: 2.0579 - val_acc: 0.5058\n",
            "Epoch 277/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3204 - acc: 0.8865 - val_loss: 1.9857 - val_acc: 0.5096\n",
            "Epoch 278/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3018 - acc: 0.8888 - val_loss: 2.0336 - val_acc: 0.5087\n",
            "Epoch 279/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3007 - acc: 0.8952 - val_loss: 2.1921 - val_acc: 0.5077\n",
            "Epoch 280/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3018 - acc: 0.8920 - val_loss: 2.1302 - val_acc: 0.5096\n",
            "Epoch 281/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2876 - acc: 0.8942 - val_loss: 2.1286 - val_acc: 0.5125\n",
            "Epoch 282/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3128 - acc: 0.8939 - val_loss: 2.0574 - val_acc: 0.5164\n",
            "Epoch 283/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3047 - acc: 0.8952 - val_loss: 2.1170 - val_acc: 0.5135\n",
            "Epoch 284/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3354 - acc: 0.8849 - val_loss: 1.9035 - val_acc: 0.5202\n",
            "Epoch 285/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3087 - acc: 0.8920 - val_loss: 2.0115 - val_acc: 0.5077\n",
            "Epoch 286/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2835 - acc: 0.8946 - val_loss: 2.0039 - val_acc: 0.5193\n",
            "Epoch 287/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3144 - acc: 0.8891 - val_loss: 2.0396 - val_acc: 0.5116\n",
            "Epoch 288/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3138 - acc: 0.8939 - val_loss: 2.0969 - val_acc: 0.5135\n",
            "Epoch 289/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3073 - acc: 0.8955 - val_loss: 2.0167 - val_acc: 0.5202\n",
            "Epoch 290/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3085 - acc: 0.8923 - val_loss: 2.1045 - val_acc: 0.5116\n",
            "Epoch 291/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3014 - acc: 0.8923 - val_loss: 2.0981 - val_acc: 0.5212\n",
            "Epoch 292/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3224 - acc: 0.8885 - val_loss: 2.0778 - val_acc: 0.5212\n",
            "Epoch 293/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2978 - acc: 0.8910 - val_loss: 2.0060 - val_acc: 0.5173\n",
            "Epoch 294/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2918 - acc: 0.8978 - val_loss: 2.0475 - val_acc: 0.5125\n",
            "Epoch 295/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2755 - acc: 0.9020 - val_loss: 2.0783 - val_acc: 0.5164\n",
            "Epoch 296/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3067 - acc: 0.8917 - val_loss: 1.9908 - val_acc: 0.5173\n",
            "Epoch 297/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2938 - acc: 0.8991 - val_loss: 2.0345 - val_acc: 0.5222\n",
            "Epoch 298/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2919 - acc: 0.8971 - val_loss: 2.0928 - val_acc: 0.5173\n",
            "Epoch 299/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3169 - acc: 0.8849 - val_loss: 2.1192 - val_acc: 0.5010\n",
            "Epoch 300/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3200 - acc: 0.8869 - val_loss: 2.1279 - val_acc: 0.5173\n",
            "Epoch 301/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3126 - acc: 0.8865 - val_loss: 2.0119 - val_acc: 0.5106\n",
            "Epoch 302/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2872 - acc: 0.9013 - val_loss: 2.0836 - val_acc: 0.5096\n",
            "Epoch 303/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2808 - acc: 0.8984 - val_loss: 2.1448 - val_acc: 0.5212\n",
            "Epoch 304/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2952 - acc: 0.8936 - val_loss: 2.0919 - val_acc: 0.5164\n",
            "Epoch 305/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3092 - acc: 0.8920 - val_loss: 1.9738 - val_acc: 0.5125\n",
            "Epoch 306/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3265 - acc: 0.8846 - val_loss: 2.1218 - val_acc: 0.5260\n",
            "Epoch 307/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3066 - acc: 0.8869 - val_loss: 2.0746 - val_acc: 0.5231\n",
            "Epoch 308/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2948 - acc: 0.8952 - val_loss: 2.0888 - val_acc: 0.5270\n",
            "Epoch 309/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2960 - acc: 0.8926 - val_loss: 2.0370 - val_acc: 0.5289\n",
            "Epoch 310/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2892 - acc: 0.8930 - val_loss: 2.1491 - val_acc: 0.5222\n",
            "Epoch 311/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3062 - acc: 0.8965 - val_loss: 2.1346 - val_acc: 0.5337\n",
            "Epoch 312/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3228 - acc: 0.8917 - val_loss: 2.0175 - val_acc: 0.5279\n",
            "Epoch 313/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2969 - acc: 0.8923 - val_loss: 2.0098 - val_acc: 0.5308\n",
            "Epoch 314/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2763 - acc: 0.8955 - val_loss: 2.1007 - val_acc: 0.5366\n",
            "Epoch 315/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3007 - acc: 0.8949 - val_loss: 2.1775 - val_acc: 0.5241\n",
            "Epoch 316/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3148 - acc: 0.8875 - val_loss: 2.0853 - val_acc: 0.5183\n",
            "Epoch 317/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3172 - acc: 0.8849 - val_loss: 2.0350 - val_acc: 0.5231\n",
            "Epoch 318/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2953 - acc: 0.8962 - val_loss: 2.0742 - val_acc: 0.5250\n",
            "Epoch 319/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2768 - acc: 0.8978 - val_loss: 2.0846 - val_acc: 0.5347\n",
            "Epoch 320/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2903 - acc: 0.8946 - val_loss: 2.0568 - val_acc: 0.5125\n",
            "Epoch 321/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2882 - acc: 0.8955 - val_loss: 2.0868 - val_acc: 0.5222\n",
            "Epoch 322/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3080 - acc: 0.8827 - val_loss: 2.0658 - val_acc: 0.5222\n",
            "Epoch 323/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2869 - acc: 0.9026 - val_loss: 2.2059 - val_acc: 0.5250\n",
            "Epoch 324/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2919 - acc: 0.8968 - val_loss: 2.1765 - val_acc: 0.5058\n",
            "Epoch 325/500\n",
            "3111/3111 [==============================] - 5s 2ms/step - loss: 0.3125 - acc: 0.8891 - val_loss: 2.1795 - val_acc: 0.5067\n",
            "Epoch 326/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2869 - acc: 0.8959 - val_loss: 2.0797 - val_acc: 0.5058\n",
            "Epoch 327/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3042 - acc: 0.8917 - val_loss: 2.1959 - val_acc: 0.5125\n",
            "Epoch 328/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2709 - acc: 0.9039 - val_loss: 2.1866 - val_acc: 0.5173\n",
            "Epoch 329/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3087 - acc: 0.8923 - val_loss: 2.0734 - val_acc: 0.5154\n",
            "Epoch 330/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2750 - acc: 0.9045 - val_loss: 2.2006 - val_acc: 0.5106\n",
            "Epoch 331/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2755 - acc: 0.8978 - val_loss: 2.0447 - val_acc: 0.5164\n",
            "Epoch 332/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2923 - acc: 0.8952 - val_loss: 1.9589 - val_acc: 0.5202\n",
            "Epoch 333/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3035 - acc: 0.8930 - val_loss: 2.0348 - val_acc: 0.5106\n",
            "Epoch 334/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2997 - acc: 0.8907 - val_loss: 2.1200 - val_acc: 0.5087\n",
            "Epoch 335/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2821 - acc: 0.9029 - val_loss: 2.1078 - val_acc: 0.5173\n",
            "Epoch 336/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2788 - acc: 0.9026 - val_loss: 2.0722 - val_acc: 0.5241\n",
            "Epoch 337/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2744 - acc: 0.9013 - val_loss: 2.0605 - val_acc: 0.5250\n",
            "Epoch 338/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2658 - acc: 0.9045 - val_loss: 2.2003 - val_acc: 0.5250\n",
            "Epoch 339/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2827 - acc: 0.8965 - val_loss: 2.1824 - val_acc: 0.5193\n",
            "Epoch 340/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2758 - acc: 0.9049 - val_loss: 2.1434 - val_acc: 0.5231\n",
            "Epoch 341/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2786 - acc: 0.9023 - val_loss: 2.0938 - val_acc: 0.5231\n",
            "Epoch 342/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2782 - acc: 0.9026 - val_loss: 2.1826 - val_acc: 0.5308\n",
            "Epoch 343/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2720 - acc: 0.9032 - val_loss: 2.1848 - val_acc: 0.5135\n",
            "Epoch 344/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2756 - acc: 0.8946 - val_loss: 2.1119 - val_acc: 0.5183\n",
            "Epoch 345/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2824 - acc: 0.8997 - val_loss: 2.1589 - val_acc: 0.5145\n",
            "Epoch 346/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2700 - acc: 0.9013 - val_loss: 2.0620 - val_acc: 0.5183\n",
            "Epoch 347/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2981 - acc: 0.8897 - val_loss: 2.1687 - val_acc: 0.5173\n",
            "Epoch 348/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2881 - acc: 0.9007 - val_loss: 2.1396 - val_acc: 0.5250\n",
            "Epoch 349/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2914 - acc: 0.8971 - val_loss: 2.1299 - val_acc: 0.5096\n",
            "Epoch 350/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2814 - acc: 0.9013 - val_loss: 2.0720 - val_acc: 0.5231\n",
            "Epoch 351/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2902 - acc: 0.8997 - val_loss: 2.1165 - val_acc: 0.5308\n",
            "Epoch 352/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2932 - acc: 0.8942 - val_loss: 2.0992 - val_acc: 0.5173\n",
            "Epoch 353/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2882 - acc: 0.8942 - val_loss: 2.2833 - val_acc: 0.5067\n",
            "Epoch 354/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2968 - acc: 0.8994 - val_loss: 2.1841 - val_acc: 0.5067\n",
            "Epoch 355/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2682 - acc: 0.9039 - val_loss: 2.2274 - val_acc: 0.5164\n",
            "Epoch 356/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2672 - acc: 0.9052 - val_loss: 2.1860 - val_acc: 0.5106\n",
            "Epoch 357/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2809 - acc: 0.9010 - val_loss: 2.1225 - val_acc: 0.5193\n",
            "Epoch 358/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2877 - acc: 0.8923 - val_loss: 2.1025 - val_acc: 0.5299\n",
            "Epoch 359/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2863 - acc: 0.9081 - val_loss: 2.2195 - val_acc: 0.5077\n",
            "Epoch 360/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2943 - acc: 0.8971 - val_loss: 2.2399 - val_acc: 0.4933\n",
            "Epoch 361/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2814 - acc: 0.8984 - val_loss: 2.3049 - val_acc: 0.5010\n",
            "Epoch 362/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2820 - acc: 0.8994 - val_loss: 2.1877 - val_acc: 0.5193\n",
            "Epoch 363/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.3003 - acc: 0.8939 - val_loss: 2.1939 - val_acc: 0.5154\n",
            "Epoch 364/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2620 - acc: 0.9087 - val_loss: 2.1755 - val_acc: 0.5222\n",
            "Epoch 365/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2521 - acc: 0.9139 - val_loss: 2.1414 - val_acc: 0.5183\n",
            "Epoch 366/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2781 - acc: 0.8994 - val_loss: 2.0733 - val_acc: 0.5260\n",
            "Epoch 367/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3105 - acc: 0.8901 - val_loss: 2.1274 - val_acc: 0.5202\n",
            "Epoch 368/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2871 - acc: 0.9026 - val_loss: 2.1588 - val_acc: 0.5183\n",
            "Epoch 369/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2730 - acc: 0.9039 - val_loss: 2.1089 - val_acc: 0.5183\n",
            "Epoch 370/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2596 - acc: 0.9094 - val_loss: 2.1788 - val_acc: 0.5106\n",
            "Epoch 371/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2834 - acc: 0.9042 - val_loss: 2.1674 - val_acc: 0.5241\n",
            "Epoch 372/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2709 - acc: 0.9045 - val_loss: 2.1156 - val_acc: 0.5173\n",
            "Epoch 373/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2702 - acc: 0.8984 - val_loss: 2.1780 - val_acc: 0.5067\n",
            "Epoch 374/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2830 - acc: 0.8939 - val_loss: 2.2783 - val_acc: 0.5039\n",
            "Epoch 375/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2517 - acc: 0.9068 - val_loss: 2.1951 - val_acc: 0.5106\n",
            "Epoch 376/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2834 - acc: 0.8975 - val_loss: 2.2423 - val_acc: 0.5125\n",
            "Epoch 377/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2713 - acc: 0.9026 - val_loss: 2.2017 - val_acc: 0.5154\n",
            "Epoch 378/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2766 - acc: 0.8971 - val_loss: 2.2102 - val_acc: 0.5318\n",
            "Epoch 379/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2613 - acc: 0.9090 - val_loss: 2.1134 - val_acc: 0.5279\n",
            "Epoch 380/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2969 - acc: 0.8917 - val_loss: 2.0854 - val_acc: 0.5231\n",
            "Epoch 381/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2729 - acc: 0.9110 - val_loss: 1.9583 - val_acc: 0.5347\n",
            "Epoch 382/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2666 - acc: 0.9106 - val_loss: 2.0547 - val_acc: 0.5279\n",
            "Epoch 383/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2956 - acc: 0.8968 - val_loss: 2.0980 - val_acc: 0.5154\n",
            "Epoch 384/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2670 - acc: 0.9007 - val_loss: 2.1146 - val_acc: 0.5183\n",
            "Epoch 385/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2616 - acc: 0.9074 - val_loss: 2.1034 - val_acc: 0.5193\n",
            "Epoch 386/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2820 - acc: 0.8942 - val_loss: 2.0962 - val_acc: 0.5231\n",
            "Epoch 387/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2836 - acc: 0.8975 - val_loss: 2.1740 - val_acc: 0.5202\n",
            "Epoch 388/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.3008 - acc: 0.8965 - val_loss: 2.1481 - val_acc: 0.5125\n",
            "Epoch 389/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2607 - acc: 0.9045 - val_loss: 2.1134 - val_acc: 0.5154\n",
            "Epoch 390/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2570 - acc: 0.9039 - val_loss: 2.2947 - val_acc: 0.5106\n",
            "Epoch 391/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2630 - acc: 0.9049 - val_loss: 2.1791 - val_acc: 0.5193\n",
            "Epoch 392/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2658 - acc: 0.9087 - val_loss: 2.2063 - val_acc: 0.5096\n",
            "Epoch 393/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2895 - acc: 0.8987 - val_loss: 2.2035 - val_acc: 0.5116\n",
            "Epoch 394/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2796 - acc: 0.8949 - val_loss: 2.1046 - val_acc: 0.5135\n",
            "Epoch 395/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2942 - acc: 0.8968 - val_loss: 2.1982 - val_acc: 0.5096\n",
            "Epoch 396/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2570 - acc: 0.9068 - val_loss: 2.1681 - val_acc: 0.5135\n",
            "Epoch 397/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2879 - acc: 0.8984 - val_loss: 2.2311 - val_acc: 0.5125\n",
            "Epoch 398/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2776 - acc: 0.8991 - val_loss: 2.2605 - val_acc: 0.5154\n",
            "Epoch 399/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2901 - acc: 0.8933 - val_loss: 2.1630 - val_acc: 0.5222\n",
            "Epoch 400/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2853 - acc: 0.8994 - val_loss: 2.0826 - val_acc: 0.5202\n",
            "Epoch 401/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2810 - acc: 0.9032 - val_loss: 2.1830 - val_acc: 0.5145\n",
            "Epoch 402/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2908 - acc: 0.9010 - val_loss: 2.1491 - val_acc: 0.5222\n",
            "Epoch 403/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2713 - acc: 0.9084 - val_loss: 2.1386 - val_acc: 0.5222\n",
            "Epoch 404/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2589 - acc: 0.9077 - val_loss: 2.3316 - val_acc: 0.5106\n",
            "Epoch 405/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2669 - acc: 0.9055 - val_loss: 2.2616 - val_acc: 0.5048\n",
            "Epoch 406/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2803 - acc: 0.8991 - val_loss: 2.1254 - val_acc: 0.5202\n",
            "Epoch 407/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2539 - acc: 0.9049 - val_loss: 2.1977 - val_acc: 0.5318\n",
            "Epoch 408/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2726 - acc: 0.9020 - val_loss: 2.1267 - val_acc: 0.5414\n",
            "Epoch 409/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2678 - acc: 0.8997 - val_loss: 2.1761 - val_acc: 0.5279\n",
            "Epoch 410/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2598 - acc: 0.9106 - val_loss: 2.1273 - val_acc: 0.5231\n",
            "Epoch 411/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2651 - acc: 0.9029 - val_loss: 2.2593 - val_acc: 0.5212\n",
            "Epoch 412/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2540 - acc: 0.9061 - val_loss: 2.2567 - val_acc: 0.5116\n",
            "Epoch 413/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2662 - acc: 0.9029 - val_loss: 2.1286 - val_acc: 0.5250\n",
            "Epoch 414/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2814 - acc: 0.8987 - val_loss: 2.1215 - val_acc: 0.5125\n",
            "Epoch 415/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2796 - acc: 0.9007 - val_loss: 2.1015 - val_acc: 0.5222\n",
            "Epoch 416/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2510 - acc: 0.9116 - val_loss: 2.0998 - val_acc: 0.5231\n",
            "Epoch 417/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2590 - acc: 0.9090 - val_loss: 2.1343 - val_acc: 0.5116\n",
            "Epoch 418/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2745 - acc: 0.9061 - val_loss: 2.1349 - val_acc: 0.5106\n",
            "Epoch 419/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2507 - acc: 0.9135 - val_loss: 2.0905 - val_acc: 0.5125\n",
            "Epoch 420/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2505 - acc: 0.9126 - val_loss: 2.3269 - val_acc: 0.5029\n",
            "Epoch 421/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2474 - acc: 0.9084 - val_loss: 2.2918 - val_acc: 0.5260\n",
            "Epoch 422/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2521 - acc: 0.9106 - val_loss: 2.3340 - val_acc: 0.5125\n",
            "Epoch 423/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2536 - acc: 0.9148 - val_loss: 2.2257 - val_acc: 0.5154\n",
            "Epoch 424/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2585 - acc: 0.9103 - val_loss: 2.1872 - val_acc: 0.5125\n",
            "Epoch 425/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2654 - acc: 0.9036 - val_loss: 2.2720 - val_acc: 0.5164\n",
            "Epoch 426/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2531 - acc: 0.9148 - val_loss: 2.3659 - val_acc: 0.5106\n",
            "Epoch 427/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2896 - acc: 0.9000 - val_loss: 2.2093 - val_acc: 0.5067\n",
            "Epoch 428/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2561 - acc: 0.9032 - val_loss: 2.3020 - val_acc: 0.5164\n",
            "Epoch 429/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2532 - acc: 0.9113 - val_loss: 2.3364 - val_acc: 0.5106\n",
            "Epoch 430/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2747 - acc: 0.9068 - val_loss: 2.2385 - val_acc: 0.5202\n",
            "Epoch 431/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2615 - acc: 0.9081 - val_loss: 2.2777 - val_acc: 0.5222\n",
            "Epoch 432/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2653 - acc: 0.9071 - val_loss: 2.1842 - val_acc: 0.5308\n",
            "Epoch 433/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2762 - acc: 0.9000 - val_loss: 2.1994 - val_acc: 0.5260\n",
            "Epoch 434/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2721 - acc: 0.9129 - val_loss: 2.1624 - val_acc: 0.5202\n",
            "Epoch 435/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2918 - acc: 0.8959 - val_loss: 2.2173 - val_acc: 0.5250\n",
            "Epoch 436/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2621 - acc: 0.9139 - val_loss: 2.1921 - val_acc: 0.5145\n",
            "Epoch 437/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2439 - acc: 0.9126 - val_loss: 2.3039 - val_acc: 0.5106\n",
            "Epoch 438/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2613 - acc: 0.9074 - val_loss: 2.3315 - val_acc: 0.5154\n",
            "Epoch 439/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2437 - acc: 0.9174 - val_loss: 2.2969 - val_acc: 0.5154\n",
            "Epoch 440/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2751 - acc: 0.9126 - val_loss: 2.1625 - val_acc: 0.5067\n",
            "Epoch 441/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2614 - acc: 0.9084 - val_loss: 2.1677 - val_acc: 0.5260\n",
            "Epoch 442/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2556 - acc: 0.9061 - val_loss: 2.2300 - val_acc: 0.5231\n",
            "Epoch 443/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2746 - acc: 0.9084 - val_loss: 2.1297 - val_acc: 0.5212\n",
            "Epoch 444/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2553 - acc: 0.9036 - val_loss: 2.2491 - val_acc: 0.5212\n",
            "Epoch 445/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2622 - acc: 0.9116 - val_loss: 2.1859 - val_acc: 0.5318\n",
            "Epoch 446/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2630 - acc: 0.9042 - val_loss: 2.2062 - val_acc: 0.5347\n",
            "Epoch 447/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2638 - acc: 0.9065 - val_loss: 2.2020 - val_acc: 0.5356\n",
            "Epoch 448/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2565 - acc: 0.9090 - val_loss: 2.3004 - val_acc: 0.5154\n",
            "Epoch 449/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2858 - acc: 0.9000 - val_loss: 2.1728 - val_acc: 0.5270\n",
            "Epoch 450/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2317 - acc: 0.9161 - val_loss: 2.2970 - val_acc: 0.5106\n",
            "Epoch 451/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2572 - acc: 0.9045 - val_loss: 2.1402 - val_acc: 0.5318\n",
            "Epoch 452/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2813 - acc: 0.9036 - val_loss: 2.2402 - val_acc: 0.5173\n",
            "Epoch 453/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2500 - acc: 0.9132 - val_loss: 2.1615 - val_acc: 0.5260\n",
            "Epoch 454/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2624 - acc: 0.9132 - val_loss: 2.2185 - val_acc: 0.5145\n",
            "Epoch 455/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2624 - acc: 0.9055 - val_loss: 2.2339 - val_acc: 0.5193\n",
            "Epoch 456/500\n",
            "3111/3111 [==============================] - 5s 2ms/step - loss: 0.2577 - acc: 0.9116 - val_loss: 2.2425 - val_acc: 0.5222\n",
            "Epoch 457/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2470 - acc: 0.9135 - val_loss: 2.2984 - val_acc: 0.5193\n",
            "Epoch 458/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2626 - acc: 0.9061 - val_loss: 2.2818 - val_acc: 0.5116\n",
            "Epoch 459/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2605 - acc: 0.9068 - val_loss: 2.2334 - val_acc: 0.5096\n",
            "Epoch 460/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2588 - acc: 0.9068 - val_loss: 2.1704 - val_acc: 0.5106\n",
            "Epoch 461/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2812 - acc: 0.9049 - val_loss: 2.1298 - val_acc: 0.5289\n",
            "Epoch 462/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2607 - acc: 0.9081 - val_loss: 2.2910 - val_acc: 0.5202\n",
            "Epoch 463/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2410 - acc: 0.9145 - val_loss: 2.2196 - val_acc: 0.5183\n",
            "Epoch 464/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2275 - acc: 0.9209 - val_loss: 2.3037 - val_acc: 0.5222\n",
            "Epoch 465/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2688 - acc: 0.8984 - val_loss: 2.1472 - val_acc: 0.5299\n",
            "Epoch 466/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2488 - acc: 0.9097 - val_loss: 2.2179 - val_acc: 0.5241\n",
            "Epoch 467/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2509 - acc: 0.9122 - val_loss: 2.1760 - val_acc: 0.5222\n",
            "Epoch 468/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2537 - acc: 0.9052 - val_loss: 2.2049 - val_acc: 0.5270\n",
            "Epoch 469/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2488 - acc: 0.9139 - val_loss: 2.1935 - val_acc: 0.5212\n",
            "Epoch 470/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2728 - acc: 0.9032 - val_loss: 2.2881 - val_acc: 0.5106\n",
            "Epoch 471/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2435 - acc: 0.9116 - val_loss: 2.1379 - val_acc: 0.5222\n",
            "Epoch 472/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2600 - acc: 0.9100 - val_loss: 2.1621 - val_acc: 0.5222\n",
            "Epoch 473/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2376 - acc: 0.9155 - val_loss: 2.2032 - val_acc: 0.5193\n",
            "Epoch 474/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2516 - acc: 0.9045 - val_loss: 2.2107 - val_acc: 0.5299\n",
            "Epoch 475/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2452 - acc: 0.9155 - val_loss: 2.1998 - val_acc: 0.5376\n",
            "Epoch 476/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2526 - acc: 0.9094 - val_loss: 2.1791 - val_acc: 0.5318\n",
            "Epoch 477/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2541 - acc: 0.9180 - val_loss: 2.1523 - val_acc: 0.5270\n",
            "Epoch 478/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2419 - acc: 0.9142 - val_loss: 2.2791 - val_acc: 0.5260\n",
            "Epoch 479/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2214 - acc: 0.9222 - val_loss: 2.3699 - val_acc: 0.5183\n",
            "Epoch 480/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2492 - acc: 0.9097 - val_loss: 2.3027 - val_acc: 0.5116\n",
            "Epoch 481/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2328 - acc: 0.9161 - val_loss: 2.2648 - val_acc: 0.5289\n",
            "Epoch 482/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2522 - acc: 0.9135 - val_loss: 2.3144 - val_acc: 0.5212\n",
            "Epoch 483/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2831 - acc: 0.9000 - val_loss: 2.2746 - val_acc: 0.5308\n",
            "Epoch 484/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2319 - acc: 0.9187 - val_loss: 2.2704 - val_acc: 0.5260\n",
            "Epoch 485/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2613 - acc: 0.8991 - val_loss: 2.2467 - val_acc: 0.5318\n",
            "Epoch 486/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2676 - acc: 0.9132 - val_loss: 2.2978 - val_acc: 0.5289\n",
            "Epoch 487/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2448 - acc: 0.9122 - val_loss: 2.3269 - val_acc: 0.5154\n",
            "Epoch 488/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2391 - acc: 0.9145 - val_loss: 2.3546 - val_acc: 0.5125\n",
            "Epoch 489/500\n",
            "3111/3111 [==============================] - 5s 1ms/step - loss: 0.2362 - acc: 0.9122 - val_loss: 2.2571 - val_acc: 0.5202\n",
            "Epoch 490/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2309 - acc: 0.9184 - val_loss: 2.3294 - val_acc: 0.5202\n",
            "Epoch 491/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2339 - acc: 0.9222 - val_loss: 2.2078 - val_acc: 0.5241\n",
            "Epoch 492/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2583 - acc: 0.9097 - val_loss: 2.2887 - val_acc: 0.5222\n",
            "Epoch 493/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2660 - acc: 0.9071 - val_loss: 2.3979 - val_acc: 0.5164\n",
            "Epoch 494/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2574 - acc: 0.9074 - val_loss: 2.3081 - val_acc: 0.5183\n",
            "Epoch 495/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2338 - acc: 0.9216 - val_loss: 2.3517 - val_acc: 0.5212\n",
            "Epoch 496/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2408 - acc: 0.9126 - val_loss: 2.2644 - val_acc: 0.5202\n",
            "Epoch 497/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2531 - acc: 0.9087 - val_loss: 2.3326 - val_acc: 0.5145\n",
            "Epoch 498/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2690 - acc: 0.9049 - val_loss: 2.3248 - val_acc: 0.5145\n",
            "Epoch 499/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2280 - acc: 0.9212 - val_loss: 2.3083 - val_acc: 0.5106\n",
            "Epoch 500/500\n",
            "3111/3111 [==============================] - 4s 1ms/step - loss: 0.2201 - acc: 0.9196 - val_loss: 2.3403 - val_acc: 0.5106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-239-cada4f3ee13f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcnnet_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnnet_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnnet_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnnet_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Time to train Network {time.time() - start}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'history'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIVXxYcoX3vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = np.reshape(hist,(4,i*epoch_fold))\n",
        "plt.plot(hist[0]); plt.plot(hist[1])\n",
        "plt.legend(['train','val'], loc= 'lower left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJHmNs4rI193",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGr3uob-Yy6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(hist[2]); plt.plot(hist[3])\n",
        "plt.legend(['train', 'val'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iH_gy7PNM9s",
        "colab_type": "text"
      },
      "source": [
        "# Model Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fLGloKK5l-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "885a04a3-80b7-4959-b172-00e3edb2a623"
      },
      "source": [
        "y_predicted = cnnet.predict(X, batch_size=32, verbose=1)\n",
        "\n",
        "y_preds = []\n",
        "for row in y_predicted:\n",
        "    index, value = max(enumerate(row), key=operator.itemgetter(1))\n",
        "    y_preds.append(index)\n",
        "\n",
        "print (\"\" )   \n",
        "print (confusion_matrix(chunks_facies_cnn, y_preds))\n",
        "print ('Model F1 score',f1_score(chunks_facies_cnn, y_preds, average='weighted'))\n",
        "print('Model Accuracy Score',accuracy_score(chunks_facies_cnn,y_preds))"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4149/4149 [==============================] - 2s 362us/step\n",
            "\n",
            "[[259   6   3   0   0   0   0   0   0]\n",
            " [  2 878  57   1   2   0   0   0   0]\n",
            " [  0  84 692   0   2   0   0   2   0]\n",
            " [  0   0   0 217  11  34   0   9   0]\n",
            " [  0   0   0   6 191  71   0  28   0]\n",
            " [  0   0   1   1   1 524   3  52   0]\n",
            " [  0   0   0   3   2   6 121   9   0]\n",
            " [  0   0   0   1   2  52   0 631   0]\n",
            " [  0   0   0   0   0  15   0  46 124]]\n",
            "Model F1 score 0.8758738371759398\n",
            "Model Accuracy Score 0.8765967703060978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-SAVOJc6C_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "545da005-53dc-44ad-be9f-88e710f8106c"
      },
      "source": [
        "conf  = confusion_matrix(chunks_facies_cnn,y_preds)\n",
        "\n",
        "adjacent_facies = np.array([[1], [0,2], [1], [4], [3,5], [4,6,7], [5,7], [5,6,8], [6,7]])\n",
        "accuracy_adj(conf,adjacent_facies)"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9744516751024344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj7gkdRk6Rgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "238c5dd6-8f2d-4ba7-ce3b-233ed634b199"
      },
      "source": [
        "X_test = chunks_cnn_test\n",
        "\n",
        "X_test = X_test.reshape((chunks_cnn_test.shape[0], chunks_cnn_test.shape[1], chunks_cnn_test.shape[2], 1))\n",
        "\n",
        "\n",
        "y_predicted = cnnet.predict(X_test, batch_size=32, verbose=1)\n",
        "\n",
        "y_preds = []\n",
        "for row in y_predicted:\n",
        "    index, value = max(enumerate(row), key=operator.itemgetter(1))\n",
        "    y_preds.append(index)\n",
        "y_preds = np.array(y_preds)+1   \n",
        "print(y_preds)"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "830/830 [==============================] - 0s 376us/step\n",
            "[5 5 8 8 8 8 8 8 8 5 5 5 5 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6\n",
            " 6 6 6 5 5 5 5 5 5 8 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 2 2 1 1 1\n",
            " 1 1 1 1 1 1 9 9 9 9 9 8 8 8 8 8 8 8 8 8 8 6 6 8 8 6 8 5 5 5 6 5 5 5 5 5 5\n",
            " 5 5 5 5 8 8 8 8 8 8 8 8 8 6 6 6 6 6 6 6 8 8 8 8 8 6 6 6 6 6 6 6 6 8 8 2 3\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 8 8 8 8 8 8 8 8 9 9 9 9 9 8 9 9 8 8 7\n",
            " 7 8 8 8 8 8 8 8 8 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 8 8 8 8 8 8 8 8 8\n",
            " 8 8 8 8 8 8 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 8 8 8 8 8 8 8 8 8 8\n",
            " 8 8 6 6 6 6 5 2 2 2 2 2 3 3 2 2 2 2 2 3 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9\n",
            " 9 8 8 8 8 8 8 8 8 8 8 8 8 8 8 1 9 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
            " 8 5 8 8 8 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 2 3 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 8 8 8 8 8 8 8 8\n",
            " 6 5 5 5 6 4 4 4 4 4 4 6 6 6 6 5 6 6 4 6 6 6 8 6 8 9 8 8 8 8 8 8 8 8 8 8 6\n",
            " 6 6 6 6 6 6 6 6 6 6 6 6 6 4 4 4 4 4 4 8 8 8 8 8 6 6 6 6 6 6 6 5 3 3 3 3 2\n",
            " 3 2 2 3 3 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 8 8 8 8 8 8 8 8 8 8 8 8\n",
            " 6 6 7 6 6 6 6 6 6 6 8 8 6 6 6 6 6 6 8 8 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 3 3\n",
            " 3 8 8 8 8 8 8 8 8 8 8 8 8 6 6 8 8 8 8 8 8 8 8 8 6 6 6 8 3 3 3 3 3 3 3 3 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 3 3 8 8 8 8 8 8 8 8 8 8 2 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 3 3 8 8 8 8 8 6 6 8 8 6 6 6 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 7 7 8 8\n",
            " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 6 6 6 6 6 6 8 8 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 8 8 8 8 8 8 8 8 8 8 8\n",
            " 8 8 8 8 8 8 8 8 6 6 6 6 6 8 8 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
            " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 4 5 5 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5\n",
            " 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cHVpRkY6YH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = pd.read_csv(\"/content/gdrive/My Drive/Data/validation_data_nofacies_online.csv\")\n",
        "test_data['Facies'] = pd.Series(y_preds)\n",
        "test_data.to_csv(\"/content/gdrive/My Drive/Data/validation_data_with_facies_new.csv\")"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v5BlFX97BgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "f4c9b754-6d6d-4964-a1d3-b82d4e9da92f"
      },
      "source": [
        "print (test_data.head())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Formation Well Name   Depth      GR  ...     PE  NM_M  RELPOS  Facies\n",
            "0     A1 SH    STUART  2808.0  66.276  ...  3.591     1   1.000       2\n",
            "1     A1 SH    STUART  2808.5  77.252  ...  3.341     1   0.978       2\n",
            "2     A1 SH    STUART  2809.0  82.899  ...  3.064     1   0.956       2\n",
            "3     A1 SH    STUART  2809.5  80.671  ...  2.977     1   0.933       2\n",
            "4     A1 SH    STUART  2810.0  75.971  ...  3.020     1   0.911       2\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB6mG0p37zJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33ebf317-837a-4007-c19d-473b4b31d5f6"
      },
      "source": [
        "set(y_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1, 2, 3, 4, 5, 6, 7, 8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNQ4rTTZNuwU",
        "colab_type": "text"
      },
      "source": [
        "# Prediction on Blind Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIId4q6a8vxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "b94f1342-d3b2-4626-8a83-b7e90650f113"
      },
      "source": [
        "blind_data = pd.read_csv('/content/gdrive/My Drive/Data/blind_stuart_crawford_core_facies.csv')\n",
        "blind_data.head()"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WellName</th>\n",
              "      <th>Depth.ft</th>\n",
              "      <th>LithCode</th>\n",
              "      <th>LithLabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>STUART</td>\n",
              "      <td>2807.5</td>\n",
              "      <td>3</td>\n",
              "      <td>NM Shly Silt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>STUART</td>\n",
              "      <td>2808.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NM Shly Silt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>STUART</td>\n",
              "      <td>2808.5</td>\n",
              "      <td>3</td>\n",
              "      <td>NM Shly Silt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>STUART</td>\n",
              "      <td>2809.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NM Shly Silt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>STUART</td>\n",
              "      <td>2809.5</td>\n",
              "      <td>3</td>\n",
              "      <td>NM Shly Silt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  WellName  Depth.ft  LithCode     LithLabel\n",
              "0   STUART    2807.5         3  NM Shly Silt\n",
              "1   STUART    2808.0         3  NM Shly Silt\n",
              "2   STUART    2808.5         3  NM Shly Silt\n",
              "3   STUART    2809.0         3  NM Shly Silt\n",
              "4   STUART    2809.5         3  NM Shly Silt"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqouuW-Q9YZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def merge_test(blind_data, test_data):\n",
        "  columns = blind_data.WellName.unique()\n",
        "  merge_col = 0\n",
        "  for column in columns:\n",
        "    blind = blind_data[blind_data['WellName'] == column]\n",
        "    test = test_data[test_data['Well Name']==column]\n",
        "    if type(merge_col) is int:\n",
        "      merge_col = pd.merge(blind, test, how = 'inner', left_on = 'Depth.ft', right_on= 'Depth')\n",
        "    else:\n",
        "      merge_col_2 = pd.merge(blind, test, how = 'inner', left_on = 'Depth.ft', right_on= 'Depth')\n",
        "  y_true = np.concatenate((merge_col.LithCode.values, merge_col_2.LithCode.values), axis = 0)\n",
        "  y_pred = np.concatenate((merge_col.Facies.values, merge_col_2.Facies.values), axis = 0)\n",
        "  return accuracy_score(y_true, y_pred)*100"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVE_jwtBQ5Sq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "30bd70ab-2c58-4b3b-a720-a83e6c6e624a"
      },
      "source": [
        "merge_test(blind_data, test_data)"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.203955500618047"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    }
  ]
}